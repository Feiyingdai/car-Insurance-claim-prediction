# 🚗 Car Insurance Claim Prediction with XGBoost

Predicting whether a driver will file a car insurance claim based on demographic, vehicle, and behavioral data. This project involves a full ML pipeline: from preprocessing and feature engineering to model tuning and business-oriented risk stratification.

---

### 📚 Table of Contents

- [🌟 Project Overview](#-project-overview)
- [📊 Dataset Overview](#-dataset-overview)
- [🚀 Quick Start](#-quick-start)
- [🧩 Feature Groups](#-feature-groups)
- [📦 Project Phases & To-Do List](#-project-phases--to-do-list)
- [🌟 Final Deliverables](#-final-deliverables)
- [📊 Results Summary](#-results-summary)
- [📈 Model Evaluation & Business Interpretation](#model-evaluation--business-interpretation)
- [📦 Tech Stack](#-tech-stack)
- [📁 Project Structure](#-project-structure)
- [🚫 Notes](#-notes)
- [📄 License & Contribution](#-license--contribution)

---

### 🌟 Project Overview

#### Backgorund:

In recent years, Tesla's intelligent systems and high performance have gained significant market traction. However, some models such as Model Y and Cybertruck exhibit elevated claim frequencies and costs, attracting attention from insurers and regulators. These trends are driven by:
- High repair costs associated with intelligent systems
- Complex Autopilot-related accident factors
- Heterogeneous driver behaviors and vehicle usage scenarios
This poses increased underwriting and payout risks for insurers.
The project proposes building a machine learning-based dynamic risk prediction model to modernize the traditional actuarial approach, leveraging data-driven modeling to quantify risk more accurately.

#### Objective:

Predict whether a driver will make a claim (binary classification), enabling data-driven risk stratification and personalized insurance management.

#### Business Applications:

💰 Risk-based Premium Adjustment
Adjust insurance pricing based on predicted claim probabilities

🛡️ Tailored Underwriting Rules
Define acceptance thresholds or policy conditions based on risk profiles

🚘 Proactive Behavioral Interventions
Identify high-risk drivers early and offer training, incentives, or personalized feedback to reduce claim likelihood

---

### 📊 Dataset Overview

Training set: 416,000+ rows

Test set: 890,000+ rows

Target variable: target (1 = made a claim, 0 = no claim)

---

### 🚀 Quick Start

To get started quickly, follow these steps:


#### 1. Clone the repository

```bash
git clone https://github.com/Feiyingdai/Car-Insurance-Claim-Prediction.git
cd Car-Insurance-Claim-Prediction
```


#### 2. Install required packages

```bash
pip install -r requirements.txt
```

Or install manually:

```bash
pip install pandas numpy scikit-learn xgboost optuna shap matplotlib seaborn
```

#### 3. Run the notebook

Open the notebook using Jupyter or Colab:

```bash
jupyter notebook notebooks/car_insurance_claim_prediction.ipynb
```


#### 4. Use the sample dataset

A small sample dataset `sample_data.csv` (100 rows) is included in the `data/` folder for testing and quick experimentation.

```python
# Load sample data
import pandas as pd
df = pd.read_csv('data/sample_data.csv')
df.head()
```
---


### 🧩 Feature Groups

**Individual Info**

ps_ind_* : Age group, license type, profession, training participation...

**Car Features**

ps_car_* : Vehicle type, battery health, charging data, Autopilot...

**Region Features**

ps_reg_* : Climate, traffic, charger density...

**Driving Behavior**

ps_calc_* : Acceleration/braking aggressiveness, high mileage behavior...

---

### 📦 Project Phases & To-Do List
#### ✅ Phase 1: Data Preparation & Cleaning

- Balance target class using techniques like Borderline SMOTE

- Handle missing values and outliers

- Transform skewed variables if needed

#### ✅ Phase 2: Feature Engineering

- Smoothed target encoding with noise

- Polynomial and interaction features

- Gain/weight-based feature selection

#### ✅ Phase 3: Model Development & Tuning

- Model: XGBoost (with L1/L2 regularization)

- Nested Optuna tuning (XGBoost hyperparameters & target encoding hyperparameters)

- 10-fold stratified cross-validation

#### ✅ Phase 4: Interpretation & Risk Stratification

- AUC Score, ROC Curve

- KS Score and Probability thresholds for claim risk segmentation of validation dataset

- Recall of validation dataset

- SHAP Feature Importance

#### ✅ Phase 5: Prediction of Test Dataset

- Final test set prediction is averaged over 10 models (Cross-Validation Ensembling)

---

### 🌟 Final Deliverables

| Deliverable        | Description                                           |
|--------------------|-------------------------------------------------------|
| Trained Model      | XGBoost model with tuned hyperparameters             |
| Feature Set        | Finalized engineered feature matrix                  |
| Evaluation         | AUC Score, ROC Curve, KS score, Recall              |
| Prediction         | Out-of-sample prediction on test dataset             |


---

### 📊 Results Summary

| Metric                     | Result     |
|----------------------------|------------|
| AUC                        | 0.86       |
| High-Risk Driver Recall    | 65%        |
| KS Score                   | 0.64       |

---

### Model Evaluation & Business Interpretation

**1. 📈 Cross-Validation Results (10 Folds)**

| Fold | AUC   |
|------|-------|
| 1    | 0.8651 |
| 2    | 0.8652 |
| 3    | 0.8659|
| 4    | 0.8685 |
| 5    | 0.8767|
| 6    | 0.8669 |
| 7    | 0.8670|
| 8    | 0.8669 |
| 9    | 0.8619 |
| 10   | 0.8638 |
| **Avg** | **0.8666** |

**KS Score (avg):** 0.64  
**Recall at KS Threshold (avg):** 0.65

**2. 📈 ROC Curve**

Model performance across validation folds:

![ROC Curve](image/roc.png)

   
**3. 📌 Business Interpretation**

By stratifying drivers based on optimal threshold (KS=0.64), we can segment the population into low-risk and high-risk groups, enabling targeted actions across pricing, underwriting, and behavioral strategies:

**🔎 Risk-Based Premium Adjustment**

- **High-risk drivers**  
  - Apply surcharges  
  - Remove discounts such as loss-free bonus  

- **Low-risk drivers**  
  - Offer loyalty-based incentives (e.g., premium rebates or safe-driving discounts)

**🧾 Tailored Underwriting Rules**

- **High-risk drivers**  
  - Set higher deductibles  
  - Cap maximum coverage limits  
  - Require telematics device installation for behavior monitoring

- **Low-risk drivers**  
  - Enable instant policy approval  
  - Minimize documentation requirements

**🚦 Proactive Behavioral Interventions**

- **High-risk drivers**  
  - Recommend incentivized defensive driving courses  
  - Provide monthly updated risk score summaries  
  - Send personalized safe-driving reminders via email or app notifications

These measures not only improve portfolio profitability but also contribute to long-term risk reduction by encouraging safer driving behavior.

---

### 📦 Tech Stack

Language: Python 3.10+

Modeling: XGBoost 1.7+

Tuning: Optuna 3.0+

Libraries: pandas, scikit-learn, seaborn, matplotlib

---

### 📁 Project Structure

```
.
├── data/                   # Raw and processed datasets (not uploaded)
├── notebooks/              # Modeling and feature engineering notebooks
├── image/                  # Images for modeling output
├── README.md               # Project documentation
└── requirements.txt        # Dependency list
```

---

### 🚫 Notes

Dataset not uploaded due to privacy constraints.

A small sample dataset **sample_data.csv** is available in data/ folder for reproducibility.

---

### 📄 License & Contribution

**📝 License**

MIT License

**👥 Contributors**

This project was developed by Feiying Dai, as part of my personal portfolio to demonstrate risk modeling in real-world insurance applications.

